{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.data_loader import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df, incoming_df, metrology_df = load_data('train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.rename(columns={'Tool ID': 'ToolId',\n",
    "                       'Run Start Time': 'RunStartTime',\n",
    "                       'Run End Time': 'RunEndTime',\n",
    "                       'Run ID': 'RunId',\n",
    "                       'Process Step': 'ProcessStep',\n",
    "                       'Consumable Life': 'ConsumableLife',\n",
    "                       'Step ID': 'StepId',\n",
    "                       'Time Stamp': 'TimeStamp',\n",
    "                       'Sensor Name': 'SensorName',\n",
    "                       'Sensor Value': 'SensorValue'}, inplace=True)\n",
    "\n",
    "incoming_df.rename(columns={'Tool ID': 'ToolId', \n",
    "                             'Run Start Time': 'RunStartTime',\n",
    "                             'Run End Time': 'RunEndTime',\n",
    "                             'Run ID': 'RunId',\n",
    "                             'Process Step': 'ProcessStep',\n",
    "                             'Step ID': 'StepId',\n",
    "                             'Time Stamp': 'TimeStamp',\n",
    "                             'Sensor Name': 'SensorName',\n",
    "                             'Sensor Value': 'SensorValue'}, inplace=True)\n",
    "\n",
    "metrology_df.rename(columns={'Run ID': 'RunId',\n",
    "                           'Run Start Time': 'RunStartTime', \n",
    "                           'Run End Time': 'RunEndTime',   \n",
    "                           'X_index': 'X_index',\n",
    "                           'Y_index': 'Y_index',\n",
    "                           'X': 'X',\n",
    "                           'Y': 'Y',\n",
    "                           'Point Index': 'PointIndex',\n",
    "                           'Measurement': 'Measurement'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement_0</th>\n",
       "      <th>Measurement_1</th>\n",
       "      <th>Measurement_2</th>\n",
       "      <th>Measurement_3</th>\n",
       "      <th>Measurement_4</th>\n",
       "      <th>Measurement_5</th>\n",
       "      <th>Measurement_6</th>\n",
       "      <th>Measurement_7</th>\n",
       "      <th>Measurement_8</th>\n",
       "      <th>Measurement_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Measurement_39</th>\n",
       "      <th>Measurement_40</th>\n",
       "      <th>Measurement_41</th>\n",
       "      <th>Measurement_42</th>\n",
       "      <th>Measurement_43</th>\n",
       "      <th>Measurement_44</th>\n",
       "      <th>Measurement_45</th>\n",
       "      <th>Measurement_46</th>\n",
       "      <th>Measurement_47</th>\n",
       "      <th>Measurement_48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000f424f-667d-54a2-bbbd-9624c4071465</th>\n",
       "      <td>10.095791</td>\n",
       "      <td>10.156764</td>\n",
       "      <td>10.337179</td>\n",
       "      <td>10.058930</td>\n",
       "      <td>10.116625</td>\n",
       "      <td>10.113654</td>\n",
       "      <td>10.183896</td>\n",
       "      <td>10.190130</td>\n",
       "      <td>10.090914</td>\n",
       "      <td>10.150634</td>\n",
       "      <td>...</td>\n",
       "      <td>10.179591</td>\n",
       "      <td>10.067517</td>\n",
       "      <td>10.129809</td>\n",
       "      <td>10.181777</td>\n",
       "      <td>10.050453</td>\n",
       "      <td>10.164333</td>\n",
       "      <td>10.120488</td>\n",
       "      <td>10.281584</td>\n",
       "      <td>10.171318</td>\n",
       "      <td>10.043010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001466b9-ee4c-5642-8e93-0a501ce4e9d9</th>\n",
       "      <td>10.138968</td>\n",
       "      <td>10.096725</td>\n",
       "      <td>10.350078</td>\n",
       "      <td>10.115794</td>\n",
       "      <td>10.203152</td>\n",
       "      <td>10.204871</td>\n",
       "      <td>10.194956</td>\n",
       "      <td>10.116416</td>\n",
       "      <td>10.086049</td>\n",
       "      <td>10.273882</td>\n",
       "      <td>...</td>\n",
       "      <td>10.263841</td>\n",
       "      <td>10.169717</td>\n",
       "      <td>10.197792</td>\n",
       "      <td>10.287032</td>\n",
       "      <td>10.088166</td>\n",
       "      <td>10.176330</td>\n",
       "      <td>10.222062</td>\n",
       "      <td>10.321888</td>\n",
       "      <td>10.192035</td>\n",
       "      <td>10.103446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d6c65-b86f-5153-a2d8-206e59da6307</th>\n",
       "      <td>10.104243</td>\n",
       "      <td>10.209842</td>\n",
       "      <td>10.371794</td>\n",
       "      <td>10.099510</td>\n",
       "      <td>10.138044</td>\n",
       "      <td>10.124540</td>\n",
       "      <td>10.279279</td>\n",
       "      <td>10.194900</td>\n",
       "      <td>10.115012</td>\n",
       "      <td>10.166862</td>\n",
       "      <td>...</td>\n",
       "      <td>10.189573</td>\n",
       "      <td>10.086770</td>\n",
       "      <td>10.150102</td>\n",
       "      <td>10.214367</td>\n",
       "      <td>10.087978</td>\n",
       "      <td>10.213599</td>\n",
       "      <td>10.135042</td>\n",
       "      <td>10.301648</td>\n",
       "      <td>10.248628</td>\n",
       "      <td>10.080373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002fdc18-a36b-5188-a5e3-9e1d59697a6b</th>\n",
       "      <td>10.079414</td>\n",
       "      <td>10.196047</td>\n",
       "      <td>10.410978</td>\n",
       "      <td>10.030844</td>\n",
       "      <td>10.104684</td>\n",
       "      <td>10.197017</td>\n",
       "      <td>10.241707</td>\n",
       "      <td>10.085138</td>\n",
       "      <td>10.106157</td>\n",
       "      <td>10.165022</td>\n",
       "      <td>...</td>\n",
       "      <td>10.206083</td>\n",
       "      <td>10.107271</td>\n",
       "      <td>10.170462</td>\n",
       "      <td>10.158340</td>\n",
       "      <td>10.052357</td>\n",
       "      <td>10.198981</td>\n",
       "      <td>10.107771</td>\n",
       "      <td>10.314725</td>\n",
       "      <td>10.208511</td>\n",
       "      <td>10.037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004379ac-3743-5811-bb3b-d1821813b2d2</th>\n",
       "      <td>10.199996</td>\n",
       "      <td>10.216007</td>\n",
       "      <td>10.398699</td>\n",
       "      <td>10.100442</td>\n",
       "      <td>10.214250</td>\n",
       "      <td>10.218284</td>\n",
       "      <td>10.223888</td>\n",
       "      <td>10.219392</td>\n",
       "      <td>10.140936</td>\n",
       "      <td>10.333146</td>\n",
       "      <td>...</td>\n",
       "      <td>10.249334</td>\n",
       "      <td>10.162063</td>\n",
       "      <td>10.262134</td>\n",
       "      <td>10.260722</td>\n",
       "      <td>10.090795</td>\n",
       "      <td>10.248904</td>\n",
       "      <td>10.252442</td>\n",
       "      <td>10.335714</td>\n",
       "      <td>10.229129</td>\n",
       "      <td>10.083445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Measurement_0  Measurement_1  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.095791      10.156764   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.138968      10.096725   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.104243      10.209842   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.079414      10.196047   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.199996      10.216007   \n",
       "\n",
       "                                      Measurement_2  Measurement_3  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.337179      10.058930   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.350078      10.115794   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.371794      10.099510   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.410978      10.030844   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.398699      10.100442   \n",
       "\n",
       "                                      Measurement_4  Measurement_5  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.116625      10.113654   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.203152      10.204871   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.138044      10.124540   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.104684      10.197017   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.214250      10.218284   \n",
       "\n",
       "                                      Measurement_6  Measurement_7  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.183896      10.190130   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.194956      10.116416   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.279279      10.194900   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.241707      10.085138   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.223888      10.219392   \n",
       "\n",
       "                                      Measurement_8  Measurement_9  ...  \\\n",
       "RunId                                                               ...   \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.090914      10.150634  ...   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.086049      10.273882  ...   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.115012      10.166862  ...   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.106157      10.165022  ...   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.140936      10.333146  ...   \n",
       "\n",
       "                                      Measurement_39  Measurement_40  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.179591       10.067517   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.263841       10.169717   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.189573       10.086770   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.206083       10.107271   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.249334       10.162063   \n",
       "\n",
       "                                      Measurement_41  Measurement_42  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.129809       10.181777   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.197792       10.287032   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.150102       10.214367   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.170462       10.158340   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.262134       10.260722   \n",
       "\n",
       "                                      Measurement_43  Measurement_44  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.050453       10.164333   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.088166       10.176330   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.087978       10.213599   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.052357       10.198981   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.090795       10.248904   \n",
       "\n",
       "                                      Measurement_45  Measurement_46  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.120488       10.281584   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.222062       10.321888   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.135042       10.301648   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.107771       10.314725   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.252442       10.335714   \n",
       "\n",
       "                                      Measurement_47  Measurement_48  \n",
       "RunId                                                                 \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.171318       10.043010  \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.192035       10.103446  \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.248628       10.080373  \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.208511       10.037665  \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.229129       10.083445  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# impt step!!\n",
    "metrology_pivot = metrology_df.pivot_table(index='RunId',\n",
    "                                           columns='PointIndex',\n",
    "                                           values='Measurement')\n",
    "\n",
    "\n",
    "metrology_pivot.columns = [f'Measurement_{i}' for i in metrology_pivot.columns]\n",
    "\n",
    "# Spatial feature engineering??\n",
    "coord_map = metrology_df[['PointIndex', 'X', 'Y']].drop_duplicates().set_index('PointIndex')\n",
    "\n",
    "# run_start_times = metrology_df[['RunId', 'RunStartTime']].drop_duplicates().set_index('RunId')\n",
    "# metrology_pivot = metrology_pivot.join(run_start_times)\n",
    "\n",
    "\n",
    "display(metrology_pivot.head())\n",
    "\n",
    "target_columns = list(metrology_pivot.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregated features with prefix: proc_\n",
      "aggregated features with prefix: inc_\n"
     ]
    }
   ],
   "source": [
    "def create_agg_features(df, group_col='RunId', prefix=''):\n",
    "\n",
    "    print(f\"aggregated features with prefix: {prefix}\")\n",
    "\n",
    "    # Pivot sensor data first: RunId, TimeStamp, Sensor1, Sensor2, ...\n",
    "    pivot_df = df.pivot_table(index=[group_col, 'TimeStamp'],\n",
    "                              columns='SensorName',\n",
    "                              values='SensorValue',\n",
    "                              aggfunc='mean') \n",
    "    pivot_df = pivot_df.reset_index()\n",
    "    pivot_df.columns.name = None \n",
    "\n",
    "\n",
    "    sensor_cols = [col for col in pivot_df.columns if col not in [group_col, 'TimeStamp']]\n",
    "\n",
    "\n",
    "    agg_funcs = ['mean', 'std', 'min', 'max', 'median', 'skew', 'sum']\n",
    "\n",
    "\n",
    "    agg_dict = {col: agg_funcs for col in sensor_cols}\n",
    "    aggregated_features = pivot_df.groupby(group_col).agg(agg_dict)\n",
    "\n",
    "    # flatten multi-index columns\n",
    "    aggregated_features.columns = [f'{prefix}{col[0]}_{col[1]}' for col in aggregated_features.columns]\n",
    "\n",
    "\n",
    "    # def get_slope(series):\n",
    "    #      # Check for NaNs or single point data\n",
    "    #     if series.isnull().all() or len(series.dropna()) < 2:\n",
    "    #          return 0.0\n",
    "         \n",
    "    #     y = series.values\n",
    "         \n",
    "    #     x = pivot_df.loc[series.index, 'TimeStamp'].values \n",
    "    #     not_nan_mask = ~np.isnan(y)\n",
    "    #     y = y[not_nan_mask]\n",
    "    #     x = x[not_nan_mask]\n",
    "    #     if len(y) < 2:\n",
    "    #         return 0.0\n",
    "    #     X = np.vstack([x, np.ones(len(x))]).T\n",
    "    #     try:\n",
    "    #         slope, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    #         return slope\n",
    "    #     except np.linalg.LinAlgError:\n",
    "    #         return 0.0 # Or some other indicator\n",
    "\n",
    "    # print(f\"Calculating slope features for prefix: {prefix}\")\n",
    "    \n",
    "    # # Group by RunId first before applying lambda to avoid redundant pivoting\n",
    "    # grouped_pivot = pivot_df.set_index(group_col) # Set RunId as index for grouping\n",
    "    # slope_features = grouped_pivot.groupby(level=0)[sensor_cols].apply(lambda g: g.apply(get_slope))\n",
    "    # slope_features.columns = [f'{prefix}{col}_slope' for col in slope_features.columns]\n",
    "    # aggregated_features = aggregated_features.join(slope_features, on=group_col)\n",
    "\n",
    "    # --- Add Time Duration Feature ---\n",
    "    run_duration = pivot_df.groupby(group_col)['TimeStamp'].max() - pivot_df.groupby(group_col)['TimeStamp'].min()\n",
    "    aggregated_features[f'{prefix}run_duration'] = run_duration\n",
    "\n",
    "\n",
    "    return aggregated_features.reset_index() \n",
    "\n",
    "\n",
    "features_run = create_agg_features(run_df, prefix='proc_')\n",
    "\n",
    "\n",
    "features_incoming = pd.DataFrame() \n",
    "\n",
    "features_incoming = create_agg_features(incoming_df, prefix='inc_')\n",
    "\n",
    "cols_to_drop = [c for c in features_incoming.columns if 'ToolId' in c] # Example\n",
    "features_incoming = features_incoming.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Start with static features from run_df (ConsumableLife, ToolId, Recipe)\n",
    "static_features = run_df[['RunId', 'ToolId', 'ConsumableLife']].drop_duplicates(subset=['RunId'])\n",
    "if static_features['RunId'].duplicated().any():\n",
    "     static_features = static_features.groupby('RunId').first() \n",
    "else:\n",
    "     static_features = static_features.set_index('RunId')\n",
    "\n",
    "\n",
    "# merge\n",
    "final_features = static_features.join(features_run.set_index('RunId'), on='RunId')\n",
    "if not features_incoming.empty:\n",
    "    final_features = final_features.join(features_incoming.set_index('RunId'), on='RunId')\n",
    "\n",
    "\n",
    "# TODO: check if need add categorical feature for toolid\n",
    "# final_features = pd.get_dummies(final_features, columns=['ToolId'], dummy_na=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final processing/merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if not isinstance(metrology_pivot.index, pd.RangeIndex):\n",
    "     metrology_pivot = metrology_pivot.reset_index()\n",
    "\n",
    "if not isinstance(final_features.index, pd.RangeIndex):\n",
    "     final_features = final_features.reset_index()\n",
    "\n",
    "training_data = pd.merge(final_features, metrology_pivot, on='RunId', how='inner')\n",
    "\n",
    "\n",
    "feature_columns = [col for col in training_data.columns if col not in target_columns and col != 'RunId']\n",
    "X = training_data[feature_columns].drop('ToolId', axis=1)\n",
    "y = training_data[target_columns]\n",
    "run_ids_final = training_data['RunId'] \n",
    "\n",
    "\n",
    "X['inc_run_duration'] = X['inc_run_duration'].apply(lambda x: x.total_seconds())\n",
    "X['proc_run_duration'] = X['proc_run_duration'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Modelling goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "X shape: (4140, 395), y shape: (4140, 49)\n",
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Train shapes - X: (3312, 395), y: (3312, 49)\n",
      "Val shapes - X: (828, 395), y: (828, 49)\n",
      "Training fold 1...\n",
      "Training model 1/3...\n",
      "Training model 2/3...\n",
      "Training model 3/3...\n",
      "Fold 1 RMSE: 0.040572\n",
      "\n",
      "Fold 2/5\n",
      "Train shapes - X: (3312, 395), y: (3312, 49)\n",
      "Val shapes - X: (828, 395), y: (828, 49)\n",
      "Training fold 2...\n",
      "Training model 1/3...\n",
      "Training model 2/3...\n",
      "Training model 3/3...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/3...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m     73\u001b[39m     model_preds = model.predict(X_val)\n\u001b[32m     74\u001b[39m     fold_predictions.append(model_preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/sklearn/multioutput.py:274\u001b[39m, in \u001b[36m_MultiOutputEstimator.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    272\u001b[39m         routed_params.estimator.fit[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = Parallel(n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs)(\n\u001b[32m    275\u001b[39m     delayed(_fit_estimator)(\n\u001b[32m    276\u001b[39m         \u001b[38;5;28mself\u001b[39m.estimator, X, y[:, i], **routed_params.estimator.fit\n\u001b[32m    277\u001b[39m     )\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y.shape[\u001b[32m1\u001b[39m])\n\u001b[32m    279\u001b[39m )\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = func(*args, **kwargs)\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/sklearn/multioutput.py:63\u001b[39m, in \u001b[36m_fit_estimator\u001b[39m\u001b[34m(estimator, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m     61\u001b[39m     estimator.fit(X, y, sample_weight=sample_weight, **fit_params)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     estimator.fit(X, y, **fit_params)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28msuper\u001b[39m().fit(\n\u001b[32m   1399\u001b[39m         X,\n\u001b[32m   1400\u001b[39m         y,\n\u001b[32m   1401\u001b[39m         sample_weight=sample_weight,\n\u001b[32m   1402\u001b[39m         init_score=init_score,\n\u001b[32m   1403\u001b[39m         eval_set=eval_set,\n\u001b[32m   1404\u001b[39m         eval_names=eval_names,\n\u001b[32m   1405\u001b[39m         eval_sample_weight=eval_sample_weight,\n\u001b[32m   1406\u001b[39m         eval_init_score=eval_init_score,\n\u001b[32m   1407\u001b[39m         eval_metric=eval_metric,\n\u001b[32m   1408\u001b[39m         feature_name=feature_name,\n\u001b[32m   1409\u001b[39m         categorical_feature=categorical_feature,\n\u001b[32m   1410\u001b[39m         callbacks=callbacks,\n\u001b[32m   1411\u001b[39m         init_model=init_model,\n\u001b[32m   1412\u001b[39m     )\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1050\u001b[39m     params=params,\n\u001b[32m   1051\u001b[39m     train_set=train_set,\n\u001b[32m   1052\u001b[39m     num_boost_round=\u001b[38;5;28mself\u001b[39m.n_estimators,\n\u001b[32m   1053\u001b[39m     valid_sets=valid_sets,\n\u001b[32m   1054\u001b[39m     valid_names=eval_names,\n\u001b[32m   1055\u001b[39m     feval=eval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1056\u001b[39m     init_model=init_model,\n\u001b[32m   1057\u001b[39m     callbacks=callbacks,\n\u001b[32m   1058\u001b[39m )\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/lightgbm/engine.py:350\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    348\u001b[39m     booster.best_score[dataset_name][eval_name] = score\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_training_booster:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     booster.model_from_string(booster.model_to_string()).free_dataset()\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m booster\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/datasci-env/lib/python3.11/site-packages/lightgbm/basic.py:4608\u001b[39m, in \u001b[36mBooster.model_to_string\u001b[39m\u001b[34m(self, num_iteration, start_iteration, importance_type)\u001b[39m\n\u001b[32m   4605\u001b[39m     string_buffer = ctypes.create_string_buffer(actual_len)\n\u001b[32m   4606\u001b[39m     ptr_string_buffer = ctypes.c_char_p(ctypes.addressof(string_buffer))\n\u001b[32m   4607\u001b[39m     _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4608\u001b[39m         _LIB.LGBM_BoosterSaveModelToString(\n\u001b[32m   4609\u001b[39m             \u001b[38;5;28mself\u001b[39m._handle,\n\u001b[32m   4610\u001b[39m             ctypes.c_int(start_iteration),\n\u001b[32m   4611\u001b[39m             ctypes.c_int(num_iteration),\n\u001b[32m   4612\u001b[39m             ctypes.c_int(importance_type_int),\n\u001b[32m   4613\u001b[39m             ctypes.c_int64(actual_len),\n\u001b[32m   4614\u001b[39m             ctypes.byref(tmp_out_len),\n\u001b[32m   4615\u001b[39m             ptr_string_buffer,\n\u001b[32m   4616\u001b[39m         )\n\u001b[32m   4617\u001b[39m     )\n\u001b[32m   4618\u001b[39m ret = string_buffer.value.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4619\u001b[39m ret += _dump_pandas_categorical(\u001b[38;5;28mself\u001b[39m.pandas_categorical)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## TODO: Modelling goes here\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scale features for better model performance\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "print(f\"X shape: {X_scaled.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Define improved LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 8,\n",
    "    'min_child_samples': 20,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'boosting_type': 'gbdt'\n",
    "}\n",
    "\n",
    "# Set up cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "oof_predictions = np.zeros(y.shape)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "print(f\"Starting {n_splits}-fold cross-validation...\")\n",
    "\n",
    "# Training and validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    X_train, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    print(f\"Train shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "    print(f\"Val shapes - X: {X_val.shape}, y: {y_val.shape}\")\n",
    "    \n",
    "    # Create ensemble of models\n",
    "    models = [\n",
    "        MultiOutputRegressor(lgb.LGBMRegressor(**{**lgb_params, 'seed': 42})),\n",
    "        MultiOutputRegressor(lgb.LGBMRegressor(**{**lgb_params, 'seed': 84})),\n",
    "        MultiOutputRegressor(lgb.LGBMRegressor(**{**lgb_params, 'seed': 126}))\n",
    "    ]\n",
    "    \n",
    "    # Train each model\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    fold_predictions = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Training model {i + 1}/3...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        model_preds = model.predict(X_val)\n",
    "        fold_predictions.append(model_preds)\n",
    "    \n",
    "    # Average predictions from all models\n",
    "    fold_preds = np.mean(fold_predictions, axis=0)\n",
    "    oof_predictions[val_idx] = fold_preds\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val, fold_preds))\n",
    "    print(f\"Fold {fold + 1} RMSE: {fold_rmse:.6f}\")\n",
    "    \n",
    "    # Store feature importance from first LightGBM model\n",
    "    if hasattr(models[0].estimators_[0], 'feature_importances_'):\n",
    "        fold_importance = pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"importance\": models[0].estimators_[0].feature_importances_,\n",
    "            \"fold\": fold + 1\n",
    "        })\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance], axis=0)\n",
    "\n",
    "# Calculate and display overall metrics\n",
    "overall_rmse = np.sqrt(mean_squared_error(y, oof_predictions))\n",
    "print(f\"\\nOverall RMSE: {overall_rmse:.6f}\")\n",
    "\n",
    "# Display feature importance\n",
    "if not feature_importance_df.empty:\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    mean_importance = feature_importance_df.groupby(\"feature\")[\"importance\"].mean()\n",
    "    print(mean_importance.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Save predictions\n",
    "oof_predictions_df = pd.DataFrame(oof_predictions, columns=y.columns, index=y.index)\n",
    "oof_predictions_df.to_csv('oof_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2650, 4140]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moof_preds\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python_env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python_env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python_env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python_env/lib/python3.9/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2650, 4140]"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(y, oof_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample submission here to note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run ID                0\n",
       "Run Start Time        0\n",
       "Run End Time          0\n",
       "X_index               0\n",
       "Y_index               0\n",
       "X                     0\n",
       "Y                     0\n",
       "Point Index           0\n",
       "Measurement       42140\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Run Start Time</th>\n",
       "      <th>Run End Time</th>\n",
       "      <th>X_index</th>\n",
       "      <th>Y_index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Point Index</th>\n",
       "      <th>Measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-143.877551</td>\n",
       "      <td>-9.183673</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>-143.877551</td>\n",
       "      <td>27.551020</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>-137.755102</td>\n",
       "      <td>58.163265</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>-131.632653</td>\n",
       "      <td>-64.285714</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>-119.387755</td>\n",
       "      <td>88.775510</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Run ID      Run Start Time  \\\n",
       "0  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "1  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "2  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "3  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "4  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "\n",
       "         Run End Time  X_index  Y_index           X          Y  Point Index  \\\n",
       "0 2024-01-02 16:43:35        1       23 -143.877551  -9.183673            3   \n",
       "1 2024-01-02 16:43:35        1       29 -143.877551  27.551020           48   \n",
       "2 2024-01-02 16:43:35        2       34 -137.755102  58.163265           43   \n",
       "3 2024-01-02 16:43:35        3       14 -131.632653 -64.285714           20   \n",
       "4 2024-01-02 16:43:35        5       39 -119.387755  88.775510            8   \n",
       "\n",
       "   Measurement  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet('metrology_data.parquet')\n",
    "\n",
    "display(df.isna().sum())\n",
    "\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
