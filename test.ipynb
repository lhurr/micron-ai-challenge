{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.data_loader import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df, incoming_df, metrology_df = load_data('train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.rename(columns={'Tool ID': 'ToolId',\n",
    "                       'Run Start Time': 'RunStartTime',\n",
    "                       'Run End Time': 'RunEndTime',\n",
    "                       'Run ID': 'RunId',\n",
    "                       'Process Step': 'ProcessStep',\n",
    "                       'Consumable Life': 'ConsumableLife',\n",
    "                       'Step ID': 'StepId',\n",
    "                       'Time Stamp': 'TimeStamp',\n",
    "                       'Sensor Name': 'SensorName',\n",
    "                       'Sensor Value': 'SensorValue'}, inplace=True)\n",
    "\n",
    "incoming_df.rename(columns={'Tool ID': 'ToolId', \n",
    "                             'Run Start Time': 'RunStartTime',\n",
    "                             'Run End Time': 'RunEndTime',\n",
    "                             'Run ID': 'RunId',\n",
    "                             'Process Step': 'ProcessStep',\n",
    "                             'Step ID': 'StepId',\n",
    "                             'Time Stamp': 'TimeStamp',\n",
    "                             'Sensor Name': 'SensorName',\n",
    "                             'Sensor Value': 'SensorValue'}, inplace=True)\n",
    "\n",
    "metrology_df.rename(columns={'Run ID': 'RunId',\n",
    "                           'Run Start Time': 'RunStartTime', \n",
    "                           'Run End Time': 'RunEndTime',   \n",
    "                           'X_index': 'X_index',\n",
    "                           'Y_index': 'Y_index',\n",
    "                           'X': 'X',\n",
    "                           'Y': 'Y',\n",
    "                           'Point Index': 'PointIndex',\n",
    "                           'Measurement': 'Measurement'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement_0</th>\n",
       "      <th>Measurement_1</th>\n",
       "      <th>Measurement_2</th>\n",
       "      <th>Measurement_3</th>\n",
       "      <th>Measurement_4</th>\n",
       "      <th>Measurement_5</th>\n",
       "      <th>Measurement_6</th>\n",
       "      <th>Measurement_7</th>\n",
       "      <th>Measurement_8</th>\n",
       "      <th>Measurement_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Measurement_39</th>\n",
       "      <th>Measurement_40</th>\n",
       "      <th>Measurement_41</th>\n",
       "      <th>Measurement_42</th>\n",
       "      <th>Measurement_43</th>\n",
       "      <th>Measurement_44</th>\n",
       "      <th>Measurement_45</th>\n",
       "      <th>Measurement_46</th>\n",
       "      <th>Measurement_47</th>\n",
       "      <th>Measurement_48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000f424f-667d-54a2-bbbd-9624c4071465</th>\n",
       "      <td>10.095791</td>\n",
       "      <td>10.156764</td>\n",
       "      <td>10.337179</td>\n",
       "      <td>10.058930</td>\n",
       "      <td>10.116625</td>\n",
       "      <td>10.113654</td>\n",
       "      <td>10.183896</td>\n",
       "      <td>10.190130</td>\n",
       "      <td>10.090914</td>\n",
       "      <td>10.150634</td>\n",
       "      <td>...</td>\n",
       "      <td>10.179591</td>\n",
       "      <td>10.067517</td>\n",
       "      <td>10.129809</td>\n",
       "      <td>10.181777</td>\n",
       "      <td>10.050453</td>\n",
       "      <td>10.164333</td>\n",
       "      <td>10.120488</td>\n",
       "      <td>10.281584</td>\n",
       "      <td>10.171318</td>\n",
       "      <td>10.043010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001466b9-ee4c-5642-8e93-0a501ce4e9d9</th>\n",
       "      <td>10.138968</td>\n",
       "      <td>10.096725</td>\n",
       "      <td>10.350078</td>\n",
       "      <td>10.115794</td>\n",
       "      <td>10.203152</td>\n",
       "      <td>10.204871</td>\n",
       "      <td>10.194956</td>\n",
       "      <td>10.116416</td>\n",
       "      <td>10.086049</td>\n",
       "      <td>10.273882</td>\n",
       "      <td>...</td>\n",
       "      <td>10.263841</td>\n",
       "      <td>10.169717</td>\n",
       "      <td>10.197792</td>\n",
       "      <td>10.287032</td>\n",
       "      <td>10.088166</td>\n",
       "      <td>10.176330</td>\n",
       "      <td>10.222062</td>\n",
       "      <td>10.321888</td>\n",
       "      <td>10.192035</td>\n",
       "      <td>10.103446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d6c65-b86f-5153-a2d8-206e59da6307</th>\n",
       "      <td>10.104243</td>\n",
       "      <td>10.209842</td>\n",
       "      <td>10.371794</td>\n",
       "      <td>10.099510</td>\n",
       "      <td>10.138044</td>\n",
       "      <td>10.124540</td>\n",
       "      <td>10.279279</td>\n",
       "      <td>10.194900</td>\n",
       "      <td>10.115012</td>\n",
       "      <td>10.166862</td>\n",
       "      <td>...</td>\n",
       "      <td>10.189573</td>\n",
       "      <td>10.086770</td>\n",
       "      <td>10.150102</td>\n",
       "      <td>10.214367</td>\n",
       "      <td>10.087978</td>\n",
       "      <td>10.213599</td>\n",
       "      <td>10.135042</td>\n",
       "      <td>10.301648</td>\n",
       "      <td>10.248628</td>\n",
       "      <td>10.080373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002fdc18-a36b-5188-a5e3-9e1d59697a6b</th>\n",
       "      <td>10.079414</td>\n",
       "      <td>10.196047</td>\n",
       "      <td>10.410978</td>\n",
       "      <td>10.030844</td>\n",
       "      <td>10.104684</td>\n",
       "      <td>10.197017</td>\n",
       "      <td>10.241707</td>\n",
       "      <td>10.085138</td>\n",
       "      <td>10.106157</td>\n",
       "      <td>10.165022</td>\n",
       "      <td>...</td>\n",
       "      <td>10.206083</td>\n",
       "      <td>10.107271</td>\n",
       "      <td>10.170462</td>\n",
       "      <td>10.158340</td>\n",
       "      <td>10.052357</td>\n",
       "      <td>10.198981</td>\n",
       "      <td>10.107771</td>\n",
       "      <td>10.314725</td>\n",
       "      <td>10.208511</td>\n",
       "      <td>10.037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004379ac-3743-5811-bb3b-d1821813b2d2</th>\n",
       "      <td>10.199996</td>\n",
       "      <td>10.216007</td>\n",
       "      <td>10.398699</td>\n",
       "      <td>10.100442</td>\n",
       "      <td>10.214250</td>\n",
       "      <td>10.218284</td>\n",
       "      <td>10.223888</td>\n",
       "      <td>10.219392</td>\n",
       "      <td>10.140936</td>\n",
       "      <td>10.333146</td>\n",
       "      <td>...</td>\n",
       "      <td>10.249334</td>\n",
       "      <td>10.162063</td>\n",
       "      <td>10.262134</td>\n",
       "      <td>10.260722</td>\n",
       "      <td>10.090795</td>\n",
       "      <td>10.248904</td>\n",
       "      <td>10.252442</td>\n",
       "      <td>10.335714</td>\n",
       "      <td>10.229129</td>\n",
       "      <td>10.083445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Measurement_0  Measurement_1  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.095791      10.156764   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.138968      10.096725   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.104243      10.209842   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.079414      10.196047   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.199996      10.216007   \n",
       "\n",
       "                                      Measurement_2  Measurement_3  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.337179      10.058930   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.350078      10.115794   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.371794      10.099510   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.410978      10.030844   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.398699      10.100442   \n",
       "\n",
       "                                      Measurement_4  Measurement_5  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.116625      10.113654   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.203152      10.204871   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.138044      10.124540   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.104684      10.197017   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.214250      10.218284   \n",
       "\n",
       "                                      Measurement_6  Measurement_7  \\\n",
       "RunId                                                                \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.183896      10.190130   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.194956      10.116416   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.279279      10.194900   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.241707      10.085138   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.223888      10.219392   \n",
       "\n",
       "                                      Measurement_8  Measurement_9  ...  \\\n",
       "RunId                                                               ...   \n",
       "000f424f-667d-54a2-bbbd-9624c4071465      10.090914      10.150634  ...   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9      10.086049      10.273882  ...   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307      10.115012      10.166862  ...   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b      10.106157      10.165022  ...   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2      10.140936      10.333146  ...   \n",
       "\n",
       "                                      Measurement_39  Measurement_40  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.179591       10.067517   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.263841       10.169717   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.189573       10.086770   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.206083       10.107271   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.249334       10.162063   \n",
       "\n",
       "                                      Measurement_41  Measurement_42  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.129809       10.181777   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.197792       10.287032   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.150102       10.214367   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.170462       10.158340   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.262134       10.260722   \n",
       "\n",
       "                                      Measurement_43  Measurement_44  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.050453       10.164333   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.088166       10.176330   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.087978       10.213599   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.052357       10.198981   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.090795       10.248904   \n",
       "\n",
       "                                      Measurement_45  Measurement_46  \\\n",
       "RunId                                                                  \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.120488       10.281584   \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.222062       10.321888   \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.135042       10.301648   \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.107771       10.314725   \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.252442       10.335714   \n",
       "\n",
       "                                      Measurement_47  Measurement_48  \n",
       "RunId                                                                 \n",
       "000f424f-667d-54a2-bbbd-9624c4071465       10.171318       10.043010  \n",
       "001466b9-ee4c-5642-8e93-0a501ce4e9d9       10.192035       10.103446  \n",
       "002d6c65-b86f-5153-a2d8-206e59da6307       10.248628       10.080373  \n",
       "002fdc18-a36b-5188-a5e3-9e1d59697a6b       10.208511       10.037665  \n",
       "004379ac-3743-5811-bb3b-d1821813b2d2       10.229129       10.083445  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# impt step!!\n",
    "metrology_pivot = metrology_df.pivot_table(index='RunId',\n",
    "                                           columns='PointIndex',\n",
    "                                           values='Measurement')\n",
    "\n",
    "\n",
    "metrology_pivot.columns = [f'Measurement_{i}' for i in metrology_pivot.columns]\n",
    "\n",
    "# Spatial feature engineering??\n",
    "coord_map = metrology_df[['PointIndex', 'X', 'Y']].drop_duplicates().set_index('PointIndex')\n",
    "\n",
    "# run_start_times = metrology_df[['RunId', 'RunStartTime']].drop_duplicates().set_index('RunId')\n",
    "# metrology_pivot = metrology_pivot.join(run_start_times)\n",
    "\n",
    "\n",
    "display(metrology_pivot.head())\n",
    "\n",
    "target_columns = list(metrology_pivot.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregated features with prefix: proc_\n",
      "aggregated features with prefix: inc_\n"
     ]
    }
   ],
   "source": [
    "def create_agg_features(df, group_col='RunId', prefix=''):\n",
    "\n",
    "    print(f\"aggregated features with prefix: {prefix}\")\n",
    "\n",
    "    # Pivot sensor data first: RunId, TimeStamp, Sensor1, Sensor2, ...\n",
    "    pivot_df = df.pivot_table(index=[group_col, 'TimeStamp'],\n",
    "                              columns='SensorName',\n",
    "                              values='SensorValue',\n",
    "                              aggfunc='mean') \n",
    "    pivot_df = pivot_df.reset_index()\n",
    "    pivot_df.columns.name = None \n",
    "\n",
    "\n",
    "    sensor_cols = [col for col in pivot_df.columns if col not in [group_col, 'TimeStamp']]\n",
    "\n",
    "\n",
    "    agg_funcs = ['mean', 'std', 'min', 'max', 'median', 'skew', 'sum']\n",
    "\n",
    "\n",
    "    agg_dict = {col: agg_funcs for col in sensor_cols}\n",
    "    aggregated_features = pivot_df.groupby(group_col).agg(agg_dict)\n",
    "\n",
    "    # flatten multi-index columns\n",
    "    aggregated_features.columns = [f'{prefix}{col[0]}_{col[1]}' for col in aggregated_features.columns]\n",
    "\n",
    "\n",
    "    # def get_slope(series):\n",
    "    #      # Check for NaNs or single point data\n",
    "    #     if series.isnull().all() or len(series.dropna()) < 2:\n",
    "    #          return 0.0\n",
    "         \n",
    "    #     y = series.values\n",
    "         \n",
    "    #     x = pivot_df.loc[series.index, 'TimeStamp'].values \n",
    "    #     not_nan_mask = ~np.isnan(y)\n",
    "    #     y = y[not_nan_mask]\n",
    "    #     x = x[not_nan_mask]\n",
    "    #     if len(y) < 2:\n",
    "    #         return 0.0\n",
    "    #     X = np.vstack([x, np.ones(len(x))]).T\n",
    "    #     try:\n",
    "    #         slope, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    #         return slope\n",
    "    #     except np.linalg.LinAlgError:\n",
    "    #         return 0.0 # Or some other indicator\n",
    "\n",
    "    # print(f\"Calculating slope features for prefix: {prefix}\")\n",
    "    \n",
    "    # # Group by RunId first before applying lambda to avoid redundant pivoting\n",
    "    # grouped_pivot = pivot_df.set_index(group_col) # Set RunId as index for grouping\n",
    "    # slope_features = grouped_pivot.groupby(level=0)[sensor_cols].apply(lambda g: g.apply(get_slope))\n",
    "    # slope_features.columns = [f'{prefix}{col}_slope' for col in slope_features.columns]\n",
    "    # aggregated_features = aggregated_features.join(slope_features, on=group_col)\n",
    "\n",
    "    # --- Add Time Duration Feature ---\n",
    "    run_duration = pivot_df.groupby(group_col)['TimeStamp'].max() - pivot_df.groupby(group_col)['TimeStamp'].min()\n",
    "    aggregated_features[f'{prefix}run_duration'] = run_duration\n",
    "\n",
    "\n",
    "    return aggregated_features.reset_index() \n",
    "\n",
    "\n",
    "features_run = create_agg_features(run_df, prefix='proc_')\n",
    "\n",
    "\n",
    "features_incoming = pd.DataFrame() \n",
    "\n",
    "features_incoming = create_agg_features(incoming_df, prefix='inc_')\n",
    "\n",
    "cols_to_drop = [c for c in features_incoming.columns if 'ToolId' in c] # Example\n",
    "features_incoming = features_incoming.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Start with static features from run_df (ConsumableLife, ToolId, Recipe)\n",
    "static_features = run_df[['RunId', 'ToolId', 'ConsumableLife']].drop_duplicates(subset=['RunId'])\n",
    "if static_features['RunId'].duplicated().any():\n",
    "     static_features = static_features.groupby('RunId').first() \n",
    "else:\n",
    "     static_features = static_features.set_index('RunId')\n",
    "\n",
    "\n",
    "# merge\n",
    "final_features = static_features.join(features_run.set_index('RunId'), on='RunId')\n",
    "if not features_incoming.empty:\n",
    "    final_features = final_features.join(features_incoming.set_index('RunId'), on='RunId')\n",
    "\n",
    "\n",
    "# TODO: check if need add categorical feature for toolid\n",
    "# final_features = pd.get_dummies(final_features, columns=['ToolId'], dummy_na=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final processing/merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if not isinstance(metrology_pivot.index, pd.RangeIndex):\n",
    "     metrology_pivot = metrology_pivot.reset_index()\n",
    "\n",
    "if not isinstance(final_features.index, pd.RangeIndex):\n",
    "     final_features = final_features.reset_index()\n",
    "\n",
    "training_data = pd.merge(final_features, metrology_pivot, on='RunId', how='inner')\n",
    "\n",
    "\n",
    "feature_columns = [col for col in training_data.columns if col not in target_columns and col != 'RunId']\n",
    "X = training_data[feature_columns].drop('ToolId', axis=1)\n",
    "y = training_data[target_columns]\n",
    "run_ids_final = training_data['RunId'] \n",
    "\n",
    "\n",
    "X['inc_run_duration'] = X['inc_run_duration'].apply(lambda x: x.total_seconds())\n",
    "X['proc_run_duration'] = X['proc_run_duration'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Modelling goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:25:59] Starting training...\n",
      "[01:28:28] 25% complete\n",
      "[01:30:46] 50% complete\n",
      "[01:32:52] 75% complete\n",
      "\n",
      "[01:35:06] Training complete! Final RMSE: 0.0276\n",
      "\n",
      "Top 10 Most Important Features (Average across all points):\n",
      "proc_Sensor_G_skew    94.768052\n",
      "inc_Sensor_39_min     81.489898\n",
      "inc_Sensor_2_min      75.503135\n",
      "proc_Sensor_C_sum     68.643233\n",
      "proc_Sensor_E_skew    64.424527\n",
      "inc_Sensor_1_mean     60.435910\n",
      "inc_Sensor_16_min     51.756896\n",
      "inc_Sensor_10_std     49.627801\n",
      "proc_Sensor_K_sum     49.481496\n",
      "proc_Sensor_O_std     48.889496\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting training...\")\n",
    "\n",
    "# Split data - reduced validation size further\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.05, random_state=42)  # Only 5% validation\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize predictions array\n",
    "final_predictions = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "feature_importance_dict = {}\n",
    "\n",
    "total_points = y.shape[1]\n",
    "checkpoints = {12: 25, 24: 50, 36: 75}\n",
    "\n",
    "# Original successful parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Train models for each measurement point\n",
    "for point in range(total_points):\n",
    "    # Get target for this point\n",
    "    y_train_point = y_train.iloc[:, point]\n",
    "    y_val_point = y_val.iloc[:, point]\n",
    "    y_test_point = y_test.iloc[:, point]\n",
    "    \n",
    "    # Initialize models\n",
    "    models = [\n",
    "        XGBRegressor(**xgb_params, random_state=42),\n",
    "        XGBRegressor(**xgb_params, random_state=84),\n",
    "        LGBMRegressor(**lgb_params, random_state=42),\n",
    "        LGBMRegressor(**lgb_params, random_state=84)\n",
    "    ]\n",
    "\n",
    "    # Train and predict for this measurement point\n",
    "    point_predictions = []\n",
    "    point_importance = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        # Create eval set for early stopping\n",
    "        eval_set = [(X_val_scaled, y_val_point)]\n",
    "        \n",
    "        # Fit with early stopping\n",
    "        if isinstance(model, XGBRegressor):\n",
    "            model.fit(X_train_scaled, y_train_point,\n",
    "                     eval_set=eval_set,\n",
    "                     early_stopping_rounds=35,  # Increased patience\n",
    "                     eval_metric='rmse',\n",
    "                     verbose=False)\n",
    "        else:  # LightGBM\n",
    "            model.fit(X_train_scaled, y_train_point,\n",
    "                     eval_set=eval_set,\n",
    "                     early_stopping_rounds=35,  # Increased patience\n",
    "                     eval_metric='rmse',\n",
    "                     verbose=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        pred = model.predict(X_test_scaled)\n",
    "        point_predictions.append(pred)\n",
    "        \n",
    "        # Accumulate feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            point_importance += model.feature_importances_\n",
    "\n",
    "    # Average feature importance for this point\n",
    "    feature_importance_dict[f'point_{point}'] = point_importance / len(models)\n",
    "    \n",
    "    # Ensemble predictions for this point\n",
    "    point_final_predictions = np.mean(point_predictions, axis=0)\n",
    "    final_predictions[:, point] = point_final_predictions\n",
    "    \n",
    "    # Print checkpoint messages\n",
    "    if point in checkpoints:\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] {checkpoints[point]}% complete\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Training complete! Final RMSE: {overall_rmse:.4f}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_df = pd.DataFrame(feature_importance_dict)\n",
    "feature_importance_df.index = X.columns\n",
    "feature_importance_df.to_csv('feature_importance_enhanced.csv')\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (Average across all points):\")\n",
    "mean_importance = feature_importance_df.mean(axis=1)\n",
    "print(mean_importance.nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample submission here to note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run ID                0\n",
       "Run Start Time        0\n",
       "Run End Time          0\n",
       "X_index               0\n",
       "Y_index               0\n",
       "X                     0\n",
       "Y                     0\n",
       "Point Index           0\n",
       "Measurement       42140\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Run Start Time</th>\n",
       "      <th>Run End Time</th>\n",
       "      <th>X_index</th>\n",
       "      <th>Y_index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Point Index</th>\n",
       "      <th>Measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-143.877551</td>\n",
       "      <td>-9.183673</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>-143.877551</td>\n",
       "      <td>27.551020</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>-137.755102</td>\n",
       "      <td>58.163265</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>-131.632653</td>\n",
       "      <td>-64.285714</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03aa7486-bf62-5d59-b844-5f2d4a4528c4</td>\n",
       "      <td>2024-01-02 16:31:00</td>\n",
       "      <td>2024-01-02 16:43:35</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>-119.387755</td>\n",
       "      <td>88.775510</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Run ID      Run Start Time  \\\n",
       "0  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "1  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "2  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "3  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "4  03aa7486-bf62-5d59-b844-5f2d4a4528c4 2024-01-02 16:31:00   \n",
       "\n",
       "         Run End Time  X_index  Y_index           X          Y  Point Index  \\\n",
       "0 2024-01-02 16:43:35        1       23 -143.877551  -9.183673            3   \n",
       "1 2024-01-02 16:43:35        1       29 -143.877551  27.551020           48   \n",
       "2 2024-01-02 16:43:35        2       34 -137.755102  58.163265           43   \n",
       "3 2024-01-02 16:43:35        3       14 -131.632653 -64.285714           20   \n",
       "4 2024-01-02 16:43:35        5       39 -119.387755  88.775510            8   \n",
       "\n",
       "   Measurement  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet('metrology_data.parquet')\n",
    "\n",
    "display(df.isna().sum())\n",
    "\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micron-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
